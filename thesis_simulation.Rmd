---
title: "Thesis"
output:
  pdf_document: default
  html_notebook: default
---
# set working enviorement

```{r, message=FALSE, warning=FALSE}
setwd("C:/Users/kaner/OneDrive/university/second_degree/Thesis")

## Quantile regression models
library(quantreg) 

## Data Manipulation
library(reshape) 
library(dplyr) 
library(reshape2)
library(caret)

## Visualization
library(ggplot2) 
library(grid) 
library(gridExtra)
library(lattice) 
library(knitr) 
library(latex2exp)
library(cowplot)
### Shiny App
library(shiny)
library(DT)

library(isotone)
library(sqldf)


library(foreach)
library(doParallel)
```



# Auxiliary Functions



## randomize_data

```{r}
randomize_data <- function(n, error_distribution_type, error_distribution_params, 
                           x_mean, x_sd, rho = 0, p, power=1, true_coefs_x = NULL) {
  
  ## assuming same rho for all xs
  
  ## if we give p than all coefs are one, else we have to give the vector of coefs 
  if (is.null(p)) {
    p <- length(true_coefs_x) -1
  } else {
    true_coefs_x <- rep(1, (p+1))
  }
  y <- rep(0,n)
  
  randomized_data <- data.frame(matrix(NA, nrow = n, ncol = p+1))
  
  ##  add each x_i
  for (i in 1:p) {
    
    x <- rnorm(n, x_mean, x_sd)
  
    if (error_distribution_type == "norm") {
      eps <- rnorm(n, mean = 0, sd = error_distribution_params[1])
    } 
    
    else if (error_distribution_type == "weibull") {
      eps <- rweibull(n, shape =  error_distribution_params[1], scale =  error_distribution_params[2])
    }
    
    else if (error_distribution_type == "t") {
      eps <- rt(n, df = error_distribution_params[1])
    }
    
    y <- y + true_coefs_x[i+1]*(x^power) + rho*(x^power)*eps
    
    randomized_data[,i] <- x
  }
  
  ## add intercept and error
  y <- true_coefs_x[1] + eps + y
  randomized_data[,p+1] <- y
  colnames(randomized_data)[p+1] <- "y"
  
  return (randomized_data)
}
```


## compute_conditional_quantile_line
```{r}
compute_conditional_quantile_line <- function(tau_true, error_distribution_type, 
                                              error_distribution_params, rho = 0, p, true_coefs_x = NULL) {

    
  if (is.null(p)) {
    p <- length(true_coefs_x) -1
  } else {
    true_coefs_x <- rep(1, (p+1))
  }

  quan_line_coefficients <- data.frame(matrix(NA, nrow = 1, ncol = p+1))
  
  if (error_distribution_type == "norm") {
    epsilon_quantile <- qnorm(tau_true, mean = 0, sd = error_distribution_params[1])
  }
  else if (error_distribution_type == "weibull") {
    epsilon_quantile <- qweibull(tau_true, shape = error_distribution_params[1], scale = error_distribution_params[2]) 
  }
  else if (error_distribution_type == "t") {
    epsilon_quantile <- qt(tau_true, df = error_distribution_params[1]) 
  }
    
  
  quan_line_coefficients[,1] <- true_coefs_x[1] + epsilon_quantile
  for (i in 2:(p+1)) {
    quan_line_coefficients[,i] <- true_coefs_x[i] + rho * epsilon_quantile

  }
  
  return (quan_line_coefficients)
}
```


## compute_test_predictions_under_settings


```{r}
compute_test_predictions_under_settings <- function(n, error_distribution_type, error_distribution_params,
                                                n_test, test_data, x_mean, x_sd, rho = 0, p, power = 1, 
                                                bias_correction_val_size = 0.8,
                                                true_coefs_x = NULL, sample_size = 1000) {
  
  if (is.null(p)) {
    p <- length(true_coefs_x) -1
  } else {
    true_coefs_x <- rep(1, (p+1))
  }
  all_taus <- c(tau_true, taus_wrong)
 
  test_predictions = data.frame(matrix(NA, nrow = n_test*(length(all_taus)), 
                                       ncol = (sample_size + 3)))

  test_predictions_bias_correction = data.frame(matrix(NA, nrow = n_test*(length(all_taus)), 
                                                       ncol = (sample_size + 3)))
  
  test_predictions_bagged_isotonic = data.frame(matrix(NA, nrow = n_test*(length(all_taus)), 
                                                       ncol = (sample_size + 3)))

  ## compute true line and its prediction on test set
  quan_line_coefficients <- 
  compute_conditional_quantile_line(tau_true, error_distribution_type, 
                                    error_distribution_params, true_coefs_x, rho = rho, p =p)

  true_quan_line_on_test <- 
    as.matrix(cbind(rep(1,n_test),((test_data %>% dplyr::select(-c(y)))^power))) %*% c(t(quan_line_coefficients))
  
  ## compute models and predictions on test set
  for (sample in seq(1,sample_size)) {

    train_data <- randomize_data(n, error_distribution_type, error_distribution_params, 
                                 x_mean = x_mean, x_sd = x_sd, rho = rho, p = p, 
                                 power = power, true_coefs_x = true_coefs_x) 
    
    bs <- 25
    n_folds <- 5
    len <- length(train_data$y)
    folds <- createFolds(train_data$y, k = n_folds)
    
    ## fit models for all taus
    for (i in 0:(length(all_taus)-1)) {

         fit <- rq(y ~ ., tau = all_taus[(i+1)], data = train_data)
         predict <- predict(fit, test_data)
         
         ## predict on taus based on train 
         test_predictions[((n_test*i)+1):(n_test*(i+1)),1] <- rep(all_taus[(i+1)],n_test)
         test_predictions[((n_test*i)+1):(n_test*(i+1)),2] <- true_quan_line_on_test
         test_predictions[((n_test*i)+1):(n_test*(i+1)),3] <- rep("no_correction",n_test)
         test_predictions[((n_test*i)+1):(n_test*(i+1)),(sample+3)] <- predict
  

         ## bias_correction - first method  
         step_mean_test <- rep(0, length(test_data$y))
         for (b in 1:bs) {
           
            small_train_data <- sample_n(train_data,(bias_correction_val_size*len), replace = F)
            small_eval_data <- sqldf("select * from train_data except select * from small_train_data")

            fit_small_train <- rq(y ~ ., tau = all_taus[(i+1)], data = small_train_data)
            predict_on_val <- predict(fit_small_train, small_eval_data) 
            
            res_p <- gpava(z = predict_on_val, y = small_eval_data$y, 
                       solver = weighted.fractile, p = tau_true)
          
            step_function <- stepfun(x = sort(res_p$z),y = sort(c(min(res_p$x),res_p$x)))
            
            step_mean_test <- step_mean_test + step_function(predict)
            
         }
         test_predictions_bias_correction[((n_test*(i))+1):(n_test*(i+1)),1] <- rep(all_taus[(i+1)],n_test)
         test_predictions_bias_correction[((n_test*(i))+1):(n_test*(i+1)),2] <- true_quan_line_on_test
         test_predictions_bias_correction[((n_test*(i))+1):(n_test*(i+1)),3] <- rep("bias_correction_one",n_test)
         test_predictions_bias_correction[((n_test*(i))+1):(n_test*(i+1)),(sample+3)] <- (step_mean_test/bs)
         
         
         ## bias_correction - second method  
         step_mean_test <- rep(0, length(test_data$y))
         for (fold in 1:n_folds) {
           
            small_train_data <- train_data[-folds[[k]],]
            small_eval_data <- train_data[folds[[k]],]
            
            fit_small_train <- rq(y ~ ., tau = all_taus[(i+1)], data = small_train_data)
            predict_on_val <- predict(fit_small_train, small_eval_data) 
            
            res_p <- gpava(z = predict_on_val, y = small_eval_data$y, 
                        solver = weighted.fractile, p = tau_true)
           
            step_function <- stepfun(x = sort(res_p$z),y = sort(c(min(res_p$x),res_p$x)))
            
            step_mean_test <- step_mean_test + step_function(predict)

            
         }
         test_predictions_bagged_isotonic[((n_test*(i))+1):(n_test*(i+1)),1] <- rep(all_taus[(i+1)],n_test)
         test_predictions_bagged_isotonic[((n_test*(i))+1):(n_test*(i+1)),2] <- true_quan_line_on_test
         test_predictions_bagged_isotonic[((n_test*(i))+1):(n_test*(i+1)),3] <- rep("bias_correction_two",n_test)
         test_predictions_bagged_isotonic[((n_test*(i))+1):(n_test*(i+1)),(sample+3)] <- (step_mean_test/n_folds)

    }
  
  }

  colnames(test_predictions)[3] <- "method"
  colnames(test_predictions)[2] <- "true_quantile_in_x"
  colnames(test_predictions)[1] <- "quantile"
  colnames(test_predictions_bias_correction)[3] <- "method"
  colnames(test_predictions_bias_correction)[2] <- "true_quantile_in_x"
  colnames(test_predictions_bias_correction)[1] <- "quantile"
  colnames(test_predictions_bagged_isotonic)[3] <- "method"
  colnames(test_predictions_bagged_isotonic)[2] <- "true_quantile_in_x"
  colnames(test_predictions_bagged_isotonic)[1] <- "quantile"
  

  return (rbind(test_predictions,test_predictions_bias_correction, test_predictions_bagged_isotonic))

}
```

## compute_Bias_Var

```{r}

compute_Bias_Var <- function(test_predictions, n_test) {
  
  all_taus <- c(tau_true, taus_wrong)
  
  errors = data.frame()

  for (i in 1:(length(all_taus)*3)){
    
    ## remove the column of the number of quantile
    quantile_test_predictions_data <- 
      test_predictions[((n_test*(i-1))+1):(n_test*(i)),] %>% 
      dplyr::select(-c(1))
    quantile <- test_predictions[((n_test*(i-1))+1),1]
    
    quantile_test_predictions_data <- quantile_test_predictions_data %>% 
      mutate("mean_pred_in_x" = apply(quantile_test_predictions_data %>% 
                                        dplyr::select(-c(true_quantile_in_x, method)), 1,mean))
  
    Squared_Bias <- (quantile_test_predictions_data$true_quantile_in_x - 
                     quantile_test_predictions_data$mean_pred_in_x)^2

    Var <- quantile_test_predictions_data %>% 
            dplyr::select(-c(true_quantile_in_x,mean_pred_in_x,method)) %>% 
            apply(2,function (col) {(quantile_test_predictions_data$mean_pred_in_x - col)^2}) %>% 
            apply(1,mean)
  
    MSE <- quantile_test_predictions_data %>% 
          dplyr::select(-c(true_quantile_in_x,mean_pred_in_x,method)) %>% 
          apply(2,function (col) {(quantile_test_predictions_data$true_quantile_in_x - col)^2}) %>% 
          apply(1,mean)
  
    errors_quantile <- data.frame("quantile"= quantile, 
                         "true_quan" = quantile_test_predictions_data$true_quantile_in_x,
                         "method" = quantile_test_predictions_data$method,
                         "Squared_Bias" = Squared_Bias,
                         "Var" = Var,
                         "MSE" = MSE)
    
    errors <- rbind(errors, errors_quantile)}
    
  return (errors)
  }
```



# Settings for all models

```{r}
## model settings
ps <- c(1,8,15)
rhos <- c(0,1)
powers <- c(1,2)

tau_true <- 0.99
taus_wrong <- c(0.97, 0.98)

## sample settings
n_test <- 2000
ns <- c(150,300,600,1200)

x_mean <- 3
x_sd <- 0.01

## parallel
packages = c("dplyr", "quantreg", "isotone", "sqldf", "knitr", "reshape", "reshape2","caret")
```


```{r}
## distribution settings
sigmas <- c(0.01, 0.05, 0.1)

shapes <- c(0.5,1,2)
scales <- c(0.5,1,2)

dfs <- c(2,5,10)
```

# Normal Errors

$$\begin{cases}
y^{(1)}=a+bx+e_{N}\\
\\
e_{_{N}}\sim N(0,\sigma)
\end{cases}$$



```{r}
run_par <- function(p, power, rho, sigma) {
    errors_par <- data.frame()

    test_data <- randomize_data(n_test, error_distribution_type = "norm",
                                error_distribution_params = sigma,
                                x_mean = x_mean, x_sd = x_sd,p = p, power=power, rho = rho)
     for (n in ns) {
       
         test_predictions <-
           compute_test_predictions_under_settings(n, error_distribution_type = "norm",
                                               error_distribution_params = sigma,
                                               n_test = n_test, test_data = test_data,
                                               x_mean = x_mean, x_sd = x_sd, rho = rho,
                                               p = p, power = power,
                                               sample = 100)

         errors <- compute_Bias_Var(test_predictions = test_predictions, n_test = n_test)


         errors_par <- rbind(errors_par, data.frame("p" = p, 
                                                    "power" = power,
                                                    "rho"= rho,
                                                    "n" = n,
                                                    "sigma" = sigma,
                                                    errors))

     }
    return (errors_par)

}

```


```{r}
# #setup parallel backend to use many processors
# cores=detectCores()
# cl <- makeCluster(cores[1]-1) #not to overload your computer
# registerDoParallel(cl)
# 
# 
# 
# errors_normal <- data.frame()
# strptime(Sys.time(), "%Y-%m-%d %H:%M:%S")
# errors_normal <-
#   foreach(p = ps, .packages=packages, .combine=rbind) %:%
#   foreach(rho = rhos, .packages=packages, .combine=rbind) %:%
#   foreach(power = powers, .packages=packages, .combine=rbind) %:%
#   foreach(sigma = sigmas, .packages=packages, .combine=rbind) %dopar% {
#       errors = run_par(p,power, rho, sigma)
#       errors
#   }
# 
# write.csv(errors_normal, "relative_and_cv_corrections_outputs/errors_normal.csv", row.names=FALSE)
# strptime(Sys.time(), "%Y-%m-%d %H:%M:%S")
# stopCluster(cl)
```



```{r}
errors_normal <- read.csv("relative_and_cv_corrections_outputs/errors_normal.csv", sep =",")
```



# Weibull errors

$$\begin{cases}
y^{(3)}=a+bx+e_{w}\\
\\
e_{w}\sim weibull(shape=a,scale=b)
\end{cases}$$


```{r}
run_par <- function(p,power, rho, shape, scale) {
    errors_par <- data.frame()

    test_data <- randomize_data(n_test, error_distribution_type = "weibull",
                                error_distribution_params = c(shape, scale),
                                x_mean = x_mean, x_sd = x_sd,p = p,power=power, rho = rho)
     for (n in ns) {

         test_predictions <-
           compute_test_predictions_under_settings(n, error_distribution_type = "weibull",
                                               error_distribution_params = c(shape, scale),
                                               n_test = n_test, test_data = test_data,
                                               x_mean = x_mean, x_sd = x_sd, rho = rho, 
                                               p = p, power = power,
                                               sample = 100)

         errors <- compute_Bias_Var(test_predictions = test_predictions, n_test = n_test)

         errors_par <- rbind(errors_par, data.frame("p" = p, 
                                                    "power" = power,
                                                    "rho"= rho,
                                                    "n" = n,
                                                    "shape" = shape,
                                                    "scale" = scale,
                                                    errors))

     }
    return (errors_par)

}
```


```{r}
# #setup parallel backend to use many processors
# cores=detectCores()
# cl <- makeCluster(cores[1]-1) #not to overload your computer
# registerDoParallel(cl)
# # 
# strptime(Sys.time(), "%Y-%m-%d %H:%M:%S")
# 
# errors_weibull <- data.frame()
# errors_weibull <-
#   foreach(p = ps, .packages=packages, .combine=rbind) %:%
#   foreach(rho = rhos, .packages=packages, .combine=rbind) %:%
#   foreach(power = powers, .packages=packages, .combine=rbind) %:%
#   foreach(shape = shapes, .packages=packages, .combine=rbind) %:%
#   foreach(scale = scales, .packages=packages, .combine=rbind) %dopar% {
#       errors = run_par(p, power,rho, shape, scale)
#       errors
#   }
# 
# strptime(Sys.time(), "%Y-%m-%d %H:%M:%S")
# write.csv(errors_weibull, "relative_and_cv_corrections_outputs/errors_weibull.csv", row.names=FALSE)
# 
# stopCluster(cl)
```

```{r}
# errors_weibull <- read.csv("relative_and_cv_corrections_outputs/outputs/errors_weibull.csv", sep =",")
```


# t-distribution errors

$$\begin{cases}
y^{(1)}=a+bx+e_{t}\\
\\
e_{_{t}}\sim t(df)
\end{cases}$$


```{r}
run_par <- function(p, power,rho, df) {
    errors_par <- data.frame()

    test_data <- randomize_data(n_test, error_distribution_type = "t",
                                error_distribution_params = df,
                                x_mean = x_mean, x_sd = x_sd,p = p, power= power, rho = rho)
     for (n in ns) {

         test_predictions <-
           compute_test_predictions_under_settings(n, error_distribution_type = "t",
                                               error_distribution_params = df,
                                               n_test = n_test, test_data = test_data,
                                               x_mean = x_mean, x_sd = x_sd, rho = rho,
                                               p = p, power = power, sample = 100)

         errors <- compute_Bias_Var(test_predictions = test_predictions, n_test = n_test)


         errors_par <- rbind(errors_par, data.frame("p" = p, 
                                                    "power" = power,
                                                    "rho"= rho,
                                                    "n" = n,
                                                    "df" = df,
                                                    errors))

     }
    return (errors_par)

}
```


```{r}
# #setup parallel backend to use many processors
# cores=detectCores()
# cl <- makeCluster(cores[1]-1) #not to overload your computer
# registerDoParallel(cl)
# 
# 
# errors_t <- data.frame()
# strptime(Sys.time(), "%Y-%m-%d %H:%M:%S")
# errors_t <-
#   foreach(p = ps, .packages=packages, .combine=rbind) %:%
#   foreach(rho = rhos, .packages=packages, .combine=rbind) %:%
#   foreach(power = powers, .packages=packages, .combine=rbind) %:%
#   foreach(df = dfs, .packages=packages, .combine=rbind) %dopar% {
#       errors = run_par(p, power,rho, df)
#       errors
#   }
# write.csv(errors_t, "relative_and_cv_corrections_outputs/errors_t.csv", row.names=FALSE)
# strptime(Sys.time(), "%Y-%m-%d %H:%M:%S")
# stopCluster(cl)
```

```{r}
errors_t <- read.csv("relative_and_cv_corrections_outputs/errors_t.csv", sep =",")
```



# Application


```{r}
errors_normal_lin <-  errors_normal %>% dplyr::filter(power==1) 
errors_normal_pow <-  errors_normal %>% dplyr::filter(power==2) 

errors_weibull_lin <-  errors_weibull %>% dplyr::filter(power==1) 
errors_weibull_pow <-  errors_weibull %>% dplyr::filter(power==2) 

errors_t_lin <-  errors_t %>% dplyr::filter(power==1) 
errors_t_pow <-  errors_t %>% dplyr::filter(power==2) 

```


```{r}
normal_lin_melted_data_iid <- 
  errors_normal_lin %>% 
  dplyr::filter(rho==0) %>% 
  melt(id.vars = seq(1,8)) %>% 
  mutate(quantile_final = ifelse(method == "bias_correction_one", paste0(quantile,"_correction_1"), 
                                 ifelse(method == "bias_correction_two", paste0(quantile,"_correction_2"),
                                         quantile))) %>% 
  select(-c(true_quan))


normal_lin_melted_data_het <- 
  errors_normal_lin %>% 
  dplyr::filter(rho==1) %>% 
  melt(id.vars = seq(1,8)) %>% 
  mutate(quantile_final = ifelse(method == "bias_correction_one", paste0(quantile,"_correction_1"), 
                                 ifelse(method == "bias_correction_two", paste0(quantile,"_correction_2"),
                                         quantile))) %>% 
  select(-c(true_quan))

normal_pow_melted_data_iid <- 
  errors_normal_pow %>% 
  dplyr::filter(rho==0) %>% 
  melt(id.vars = seq(1,8)) %>% 
  mutate(quantile_final = ifelse(method == "bias_correction_one", paste0(quantile,"_correction_1"), 
                                 ifelse(method == "bias_correction_two", paste0(quantile,"_correction_2"),
                                         quantile))) %>% 
  select(-c(true_quan))


normal_pow_melted_data_het <- 
  errors_normal_pow %>% 
  dplyr::filter(rho==1) %>% 
  melt(id.vars = seq(1,8)) %>% 
  mutate(quantile_final = ifelse(method == "bias_correction_one", paste0(quantile,"_correction_1"), 
                                 ifelse(method == "bias_correction_two", paste0(quantile,"_correction_2"),
                                         quantile))) %>% 
  select(-c(true_quan))
```

```{r}
weibull_lin_melted_data_iid <- 
  errors_weibull_lin %>% 
  dplyr::filter(rho==0) %>% 
  melt(id.vars = seq(1,9)) %>% 
  mutate(quantile_final = ifelse(method == "bias_correction_one", paste0(quantile,"_correction_1"), 
                                 ifelse(method == "bias_correction_two", paste0(quantile,"_correction_2"),
                                         quantile))) %>% 
  select(-c( true_quan))


weibull_lin_melted_data_het <- 
  errors_weibull_lin %>% 
  dplyr::filter(rho==1) %>% 
  melt(id.vars = seq(1,9)) %>% 
  mutate(quantile_final = ifelse(method == "bias_correction_one", paste0(quantile,"_correction_1"), 
                                 ifelse(method == "bias_correction_two", paste0(quantile,"_correction_2"),
                                         quantile))) %>%   select(-c(true_quan))

weibull_pow_melted_data_iid <- 
  errors_weibull_pow%>% 
  dplyr::filter(rho==0) %>% 
  melt(id.vars = seq(1,9)) %>% 
  mutate(quantile_final = ifelse(method == "bias_correction_one", paste0(quantile,"_correction_1"), 
                                 ifelse(method == "bias_correction_two", paste0(quantile,"_correction_2"),
                                         quantile))) %>%   select(-c( true_quan))


weibull_pow_melted_data_het <- 
  errors_weibull_pow %>% 
  dplyr::filter(rho==1) %>% 
  melt(id.vars = seq(1,9)) %>% 
  mutate(quantile_final = ifelse(method == "bias_correction_one", paste0(quantile,"_correction_1"), 
                                 ifelse(method == "bias_correction_two", paste0(quantile,"_correction_2"),
                                         quantile))) %>%   select(-c(true_quan))
```



```{r, message=FALSE, warning=FALSE}
t_lin_melted_data_iid <- 
  errors_t_lin %>% 
  dplyr::filter(rho==0) %>% 
  melt(id.vars = seq(1,8)) %>% 
  mutate(quantile_final = ifelse(method == "bias_correction_one", paste0(quantile,"_correction_1"), 
                                 ifelse(method == "bias_correction_two", paste0(quantile,"_correction_2"),
                                         quantile))) %>% 
  select(-c(true_quan))


t_lin_melted_data_het <- 
  errors_t_lin %>% 
  dplyr::filter(rho==1) %>% 
  melt(id.vars = seq(1,8)) %>% 
  mutate(quantile_final = ifelse(method == "bias_correction_one", paste0(quantile,"_correction_1"), 
                                 ifelse(method == "bias_correction_two", paste0(quantile,"_correction_2"),
                                         quantile))) %>% 
  select(-c(true_quan))

t_pow_melted_data_iid <- 
  errors_t_pow %>% 
  dplyr::filter(rho==0) %>% 
  melt(id.vars = seq(1,8)) %>% 
  mutate(quantile_final = ifelse(method == "bias_correction_one", paste0(quantile,"_correction_1"), 
                                 ifelse(method == "bias_correction_two", paste0(quantile,"_correction_2"),
                                         quantile))) %>% 
  select(-c(true_quan))


t_pow_melted_data_het <- 
  errors_t_pow %>% 
  dplyr::filter(rho==1) %>% 
  melt(id.vars = seq(1,8)) %>% 
  mutate(quantile_final = ifelse(method == "bias_correction_one", paste0(quantile,"_correction_1"), 
                                 ifelse(method == "bias_correction_two", paste0(quantile,"_correction_2"),
                                         quantile))) %>% 
  select(-c(true_quan))

```


## ui 

```{r}
ui <- fluidPage(
  
  headerPanel("My Shiny Thesis"),
  submitButton("Update View", icon("angellist")),

  # Sample parameters
  verticalLayout(
    
    splitLayout(
  
        radioButtons("distribution", h5("Distribution"), 
                    choices = list("Normal" = "norm","Student's t"="t", "Weibull" = "weibull"),
                    selected = "norm"),
        
        radioButtons("rho", h5("Rho"), 
                    choices = rhos,
                    selected = 0),
        
        radioButtons("power", h5("Power"), 
            choices = powers,
            selected = 1),
        
        
        radioButtons("p", h5("P"), 
                    choices = ps,
                    selected = 1),

        
        checkboxGroupInput("taus_wrong", h5("Wrong quantiles"), 
                    choices = taus_wrong,
                    selected = 0.97),
        
        radioButtons("method", h5("Methods to show"), 
                    choices = list("Bias Correction One",
                                   "Bias Correction Two", 
                                   "No Correction", 
                                   "Show All"),
                    selected = "Show All"),
        
        checkboxGroupInput("n", h5("Train set size"),
                       choices = ns, selected = ns))),
  
  ## distribution parameters
    sidebarPanel(
            width = 3,
            h3("Distribution Parameters"),
            radioButtons("sigma", h5("Sigma"),
                 choices = sigmas, selected = 0.01),
            radioButtons("df", h5("Degreed of freedom"),
                 choices = dfs, selected = 2),
            
            splitLayout(

            radioButtons("shape", h5("Shape"),
                 choices = shapes, selected = 1),
            radioButtons("scale", h5("Scale"),
                 choices = scales, selected = 1)
            
            )

     ),

  
  ## tabs of different plots
   mainPanel(
     
     tabsetPanel (
    
            ## Tab 1 - plot the errors over differnt parameters
               tabPanel ("Simulation Errors", fluid = "TRUE",
               plotOutput(outputId = "boxplot")
               ),
    
            ## tab 2
              tabPanel ("Simulation Residuls Distribution", fluid = "TRUE",
              plotOutput(outputId = "density")
               )
  
  
     )
  )
)
```



## server 

```{r}
server <- function(input, output) {
  
  distribution_data <- reactive({
    
        if (input$distribution=='weibull') {
          if (input$rho==0){
            if (input$power==1){
                chosen_distribution <- weibull_lin_melted_data_iid
            } else {
               chosen_distribution <- weibull_pow_melted_data_iid
            }
          } else {
            if (input$power==1){
               chosen_distribution <- weibull_lin_melted_data_het
            } else {
               chosen_distribution <- weibull_pow_melted_data_het

            }
          }
        } else 
          if (input$distribution=='t'){
          if (input$rho==0){
            if (input$power==1){
            chosen_distribution <- t_lin_melted_data_iid
            } else {
             chosen_distribution <- t_pow_melted_data_iid

            }
          } else {
            if (input$power==1){
            chosen_distribution <- t_lin_melted_data_het
            } else {
            chosen_distribution <- t_pow_melted_data_het

            }
          }
        } else if (input$rho==0) {
          if (input$power==1){
          chosen_distribution <- normal_lin_melted_data_iid 
          } else {
          chosen_distribution <- normal_pow_melted_data_iid 

          }
        } else {
           if (input$power==1){
          chosen_distribution <- normal_lin_melted_data_het 
           } else {
             chosen_distribution <- normal_pow_melted_data_het 

           }
        }
        
        return (data.frame(chosen_distribution))
  })


  
   filtered_data_by_params <- reactive({
          
          filtered_data_param = distribution_data()
          
          if (input$distribution == "norm") {
              filtered_data = filtered_data_param %>% 
                          dplyr::filter((n %in% input$n) & (sigma == input$sigma) & 
                                          (quantile %in% c(tau_true, input$taus_wrong)) &
                                          (rho == input$rho) & (p == input$p) & (power==input$power))
          } else if (input$distribution == "weibull") {
              filtered_data = filtered_data_param %>% 
                          dplyr::filter((n %in% input$n) & (shape == input$shape) & (scale == input$scale) &
                                        (quantile %in% c(tau_true, input$taus_wrong)) &
                                        (rho == input$rho) & (p == input$p) & (power==input$power))
          } else if (input$distribution == "t") {
              filtered_data = filtered_data_param %>% 
                          dplyr::filter((n %in% input$n) & (df == input$df) & 
                                        (quantile %in% c(tau_true, input$taus_wrong)) &
                                        (rho == input$rho) & (p == input$p) & (power==input$power))}
         
          return (data.frame(filtered_data))
     
   })
   
    method_data <- reactive({
    
        filtere_data_by_param = filtered_data_by_params()
      
        # if (input$method=="Modeling wrong quantiles") {
        #    filtere_data_by_param <- filtere_data_by_param %>% dplyr::filter(method!="with_correction")
        # } else if (input$method=="Bias Correction") {
        #    filtere_data_by_param <- filtere_data_by_param %>% dplyr::filter(method!="no_correction")
        # } else {
        #    filtere_data_by_param <- filtere_data_by_param
        # }
        # 
        return (data.frame(filtere_data_by_param))
  })
   
     
   errors_dist_data <- reactive({
     
      data <- filtered_data_by_params() %>% 
           filter(variable == "MSE" & quantile == tau_true & 
                    n == max(input$n) & p==min(input$p) & rho==min(input$rho))
     
      if (input$distribution == "norm") {
        dist <- rnorm(data$n, sd = data$sigma)
      } else if (input$distribution == "weibull") {
        dist <- rweibull(data$n, shape = data$shape, scale = data$scale)
      } else if (input$distribution == "t") {
        dist <- rt(data$n, df =  data$df)
      } 
      return (data_frame(x = dist))
   })
 
   # y_x_data <- reactive({
   #   ## show y~x for p=1
   #  ## not working
   #   
   #   error_distribution_params_input <- ifelse(input$distribution == "norm", 
   #                                       max(input$sigma), 
   #                                       ifelse(input$distribution == "weibull",
   #                                              c(max(input$shape), max(input$scale)),
   #                                              max(input$df)))
   # 
   #   randomized_data <- randomize_data(n = max(input$n), 
   #                          error_distribution_type = input$distribution, 
   #                          error_distribution_params = error_distribution_params_input, 
   #                          x_mean = x_mean, x_sd = x_sd, rho = max(input$rho), p = 1)
   # 
   #   return (randomized_data)
   #   
   # })
  
     output$density <- renderPlot({

        ggplot(errors_dist_data(), aes(x)) +
        geom_histogram(col = "cornflowerblue", 
                       fill = "cornflowerblue", alpha = 0.7, bins = 100) +
        labs(x = "residual value", y = "count") +
        theme_grey()  
        
        # grid.arrange(hist, dist, ncol = 2)
     })
     
  
    output$boxplot <- renderPlot({
    
        ggplot(method_data(),
         aes(x = as.factor(n), y = log(value+1),  
             fill = as.factor(quantile_final), col = as.factor(quantile_final)))+
        geom_boxplot(col = "#585858", outlier.size = 0.1)+
        facet_wrap(~ variable) + #scales="free"
        labs(x = "n", y = "log(value+1)", fill = "Quantile") +
        # scale_colour_manual(values = c("0.95" = "#9BC01C", 
        #                                "0.95_corrected" = "#C3E05E",
        #                                "0.97" = "#F52549", 
        #                                "0.97_corrected" = "#FA6775",
        #                                "0.99" = "#f48d38"))+
        # scale_fill_manual(values = c("0.95" = "#9BC01C", 
        #                                "0.95_corrected" = "#C3E05E",
        #                                "0.97" = "#F52549", 
        #                                "0.97_corrected" = "#FA6775",
        #                                "0.99" = "#f48d38"))+
        scale_fill_brewer(palette="Paired") +
        theme_grey() +
        theme(legend.position = "bottom")

     })
    


}


```

## run app

```{r}
shinyApp(ui = ui, server = server)
```


## summary of interesting cases


## Normal Distribution

```{r, fig.height=12, fig.width=12}
iid <- ggplot(normal_melted_data_iid %>% 
       dplyr::filter((p %in% c(15)) & (sigma == 0.1)  
                     & (quantile %in% c(0.97,0.99))
                     & (n %in% ns)),
       aes(x = as.factor(n), y = log(value+1), fill = as.factor(quntile_final)))+
geom_boxplot(inherit.aes = T, 
             col = "#585858", outlier.size = 0.15)+
facet_grid(~variable, scales = "free") + 
labs(x = "n", y = "log(value+1)", fill = "Method") +
scale_fill_brewer(palette="Paired") +
 # theme_light() +
theme_grey() +
theme(legend.position = "None")

  
het <- 
  ggplot(normal_melted_data_het %>% 
       dplyr::filter((p %in% c(15)) & (sigma == 0.1)  
                     & (quantile %in% c(0.97,0.99))
                     & (n %in% ns)),
       aes(x = as.factor(n), y = log(value+1), fill = as.factor(quantile_final)))+
geom_boxplot(inherit.aes = T, 
             col = "#585858", outlier.size = 0.15)+
facet_grid(~variable, scales = "free") + 
labs(x = "n", y = "log(value+1)", fill = "Method") +
scale_fill_brewer(palette="Paired") +
 # theme_light() +
theme_grey() +
theme(legend.position = "bottom")


grid.arrange(arrangeGrob(iid, top="Location model"), 
             arrangeGrob(het, top="Scale-location model"), 
             nrow = 2, heights = c(0.47,0.53))
```

```{r, fig.height=12, fig.width=12}
ggplot(t_melted_data_iid %>% 
       dplyr::filter((p %in% c(15)) & (df %in% dfs)  
                     & (quantile %in% c(0.97,0.99))
                     & (n %in% ns)),
       aes(x = as.factor(n), y = log(value+1), fill = as.factor(quantile_final)))+
geom_boxplot(inherit.aes = T, 
             col = "#585858", outlier.size = 0.15)+
facet_grid(df~variable, scales = "free") + 
labs(x = "n", y = "log(value+1)", fill = "Method") +
scale_fill_brewer(palette="Paired") +
 # theme_light() +
theme_grey() +
theme(legend.position = "None")

```


```{r, fig.height=8, fig.width=12}
ggplot(weibull_melted_data_iid %>% 
       dplyr::filter((p == 15) & (shape %in% shapes) & (scale ==1)  
                     & (quantile %in% c(0.97,0.99))
                     & (n %in% ns) ),
       aes(x = as.factor(n), y = log(value+1), fill = as.factor(quantile_final)))+
geom_boxplot(inherit.aes = T, 
             col = "#585858", outlier.size = 0.15)+
facet_grid(shape~variable, scales = "free") + 
labs(x = "n", y = "log(value+1)", fill = "Method") +
scale_fill_brewer(palette="Paired") +
 # theme_light() +
theme_grey() +
theme(legend.position = "None")

```


# Bias correction

## isotonic

```{r}
df <- 2

## model settings
true_coefs_xs <- list(rep(1,2), rep(1,6) ,rep(1,11), rep(1,21))
true_coefs_x <- rep(1,11)
rho <- 0

tau_true <- 0.99
taus_wrong <- c(0.97)

## sample settings
n_test <- 3000
ns <- c(125,250,500,1000,2000)
n <- 250
x_mean <- 1
x_sd <- 0.01

error_distribution_type <- "t"
error_distribution_params <- df
```


```{r}
test_data <- randomize_data(n_test, error_distribution_type = error_distribution_type, error_distribution_params = error_distribution_params, x_mean = x_mean, x_sd = x_sd, true_coefs_x = true_coefs_x, rho=rho)


train_data <- randomize_data(n, error_distribution_type, error_distribution_params, 
                             x_mean, x_sd, true_coefs_x, rho = rho) 

quan_line_coefficients <- compute_conditional_quantile_line(tau_true, error_distribution_type, error_distribution_params, true_coefs_x, rho = rho)

test_predictions <-
  compute_test_predictions_under_settings(n, error_distribution_type = "t",
                                          error_distribution_params = df,
                                          n_test = n_test, test_data = test_data,
                                          x_mean = x_mean, x_sd = x_sd, rho = rho)

errors <- cbind(method = "qr",
                compute_Bias_Var(test_predictions = test_predictions, n_test = n_test))


test_predictions_bias_correction <- 
  compute_test_predictions_under_settings(n, error_distribution_type = "t",
                                          error_distribution_params = df,
                                          n_test = n_test, test_data = test_data,
                                          x_mean = x_mean, x_sd = x_sd, rho = rho,
                                          bias_correction = T, val_size = 0.8)


errors_bias_corretion <- cbind(method = "bias_correction",
  compute_Bias_Var(test_predictions = test_predictions_bias_correction, n_test = n_test)) 

all_errors <- rbind(errors, errors_bias_corretion)

```

```{r}
ggplot(all_errors %>% melt(id.vars = c(1,2,3)), 
       aes(x = quantile, y = log(value+1), group = as.factor(quantile)))+
  geom_boxplot() +
  facet_grid(variable~method) +
  theme_gray()

```


## How to know when does the bias correction help


### iid errors

```{r}
normal_melted_data_iid %>% 
  group_by(p,rho,n,sigma,quantile,method,variable) %>% 
  summarise(median = median(value),
            mean = mean(value),
            min = min(value), max = max(value),
            sd = sd(value)) %>% 
  filter(variable == "MSE" & quantile %in% c(0.97,0.99) & p>1) %>% 
  select(-c(variable)) %>% 
  dcast(p+rho+n+sigma ~ paste0('method_',method), value.var = 'median') %>% 
  mutate("is_bias_correction_good" = 
           ifelse(method_bias_correction < method_true, 1, 0),
         "is_modeling_wrong_quantile_good" = 
           ifelse(method_no_correction < method_true, 1, 0)) %>% 
  select(-c(method_bias_correction, method_no_correction, method_true)) %>% 
  arrange(-is_bias_correction_good)
```


```{r}
t_melted_data_iid %>% 
  group_by(p,rho,n,df,quantile,method,variable) %>% 
  summarise(median = median(value),
            mean = mean(value),
            min = min(value), max = max(value),
            sd = sd(value)) %>% 
  filter(variable == "MSE" & quantile %in% c(0.97,0.99) & p>1) %>% 
  select(-c(variable)) %>% 
  dcast(p+rho+n+df ~ paste0('method_',method), value.var = 'median') %>% 
  mutate("is_bias_correction_good" = 
           ifelse(method_bias_correction < method_true, 1, 0),
         "is_modeling_wrong_quantile_good" = 
           ifelse(method_no_correction < method_true, 1, 0)) %>% 
  select(-c(method_bias_correction, method_no_correction, method_true)) %>% 
  arrange(-is_bias_correction_good)
```




```{r}
distribution_type = "weibull"
scale = 0.5
location = 1
rho=0

train_data <- randomize_data(1000, distribution_type, c(scale,location),
                             x_mean, x_sd, true_coefs_x, rho = rho)
    
model <- rq(y~., tau= 0.99, data = train_data)

kernel <- function(x) {
  if (abs(x)<=1) {return (0.5)}
  else (return (0))
}

train_data$y_pred <- predict(model)
train_data$res <- train_data$y - train_data$y_pred
train_data$ker <- sapply(train_data$res / bandwidth, function (x) {kernel(x)})


J_het = matrix(0, nrow=15, ncol=15)
for (i in 1:1000) {
  mat = as.vector(t(train_data[i,] %>% select(-c(y,y_pred,res,ker)))) %*% 
    as.matrix(train_data[i,] %>% select(-c(y,y_pred,res,ker)))
  
  J_het = J_het + mat
  
}
matrix_sparsity_estimator = J_het / (1000*bandwidth)


iid_estimator = (quantile(train_data$y,0.99+bandwidth) - quantile(train_data$y,0.99-bandwidth))/(2*bandwidth)

final_matrix_estimator  = solve(matrix_sparsity_estimator)

summary(model, se = "nid")


```


# Variance Expression simulations 

## Variance for quantile tau

Let $\frac{1}2<<\tau<1$, and we'll look at $\theta(\tau)=\frac{\tau(1-\tau)}{f^2(\xi(\tau))}$ as a function of $\tau$.


### normal dist:

$$\frac{\tau\left(1-\tau\right)}{\tau_{w}\left(1-\tau_{w}\right)}\leq exp\left\{ \left(\left(\varPhi^{-1}\right)^{2}\left(\tau_{w}\right)-\left(\varPhi^{-1}\right)^{2}\left(\tau\right)\right)\right\} $$

invented dist:
$$f_{\epsilon}\left(u\right)=\left|u\right|, -1<u<1$$

$$\frac{\tau\left(1-\tau\right)}{\tau_{w}\left(1-\tau_{w}\right)}\leq\frac{2\tau-1}{2\tau_{w}-1}$$


```{r, message=FALSE, warning=FALSE}
true_tau <- 0.99

results = data.frame(wrong_tau = NA, dist = NA, DSR = NA, QMR = NA)

## normal
for (wrong_tau in seq(0.5, true_tau, by = 0.005)) {
  
  mult_true <- true_tau*(1-true_tau)
  mult_wrong <- wrong_tau*(1-wrong_tau)

  quan_true <- qnorm(true_tau)
  quan_wrong <- qnorm(wrong_tau)

  DSR <- exp(quan_true^2 - quan_wrong^2)
  QMR <- mult_wrong/mult_true
  
  current <- data.frame(wrong_tau = wrong_tau, 
                        dist = "Normal Density",
                        DSR = DSR, 
                        QMR = QMR)
  results <- rbind(results, current)
}



for (wrong_tau in seq(0.5, true_tau, by = 0.005)) {
  
  mult_true <- true_tau*(1-true_tau)
  mult_wrong <- wrong_tau*(1-wrong_tau)

  quan_true <- qnorm(true_tau)
  quan_wrong <- qnorm(wrong_tau)

  DSR <- exp(quan_true^2 - quan_wrong^2)
  QMR <- mult_wrong/mult_true
  
  current <- data.frame(wrong_tau = wrong_tau, 
                        dist = "Normal Density",
                        DSR = DSR, 
                        QMR = QMR)
  results <- rbind(results, current)
}

## absolute value
for (wrong_tau in seq(0.5, true_tau, by = 0.005)) {
  
  mult_true <- true_tau*(1-true_tau)
  mult_wrong <- wrong_tau*(1-wrong_tau)

  quan_true <- 2*true_tau - 1
  quan_wrong <- 2*wrong_tau - 1

  DSR <- quan_true/quan_wrong 
  QMR <- mult_wrong/mult_true
  
  current <- data.frame(wrong_tau = wrong_tau, 
                        dist =  "Absolute Value Density",
                        DSR = DSR, 
                        QMR = QMR)
  results <- rbind(results, current)
}
```

```{r, fig.height=8, fig.width=12}
# ggplot(results[-1,] %>% melt(id = c('wrong_tau','dist')), 
#        aes(x = wrong_tau, y= value, color = variable)) +
# geom_point(size = 2) +
# xlab(TeX('$\\tau_{w}$')) +
# guides(color = guide_legend(title=NULL)) +
# scale_color_discrete(labels = lapply(c('$\\left(\\Phi^{-1}\\right)^{2}\\left(\\tau_{w}\\right)-\\left(\\Phi^{-1}\\right)^{2}\\left(\\tau\\right)$',                                 '$\\frac{\\tau\\left(1-\\tau\\right)}{\\tau_{w}\\left(1-\\tau_{w}\\right)}$'), TeX)) +
#   theme_grey()+
#   theme(legend.position = "bottom") +
#   facet_wrap(~dist)
# 

ggplot(results[-1,] %>% melt(id = c('wrong_tau','dist')), 
       aes(x = wrong_tau, y= value, color = variable)) +
geom_point(size = 1) +
xlab(TeX('$\\tau_{w}$')) +
guides(color = guide_legend(title=NULL)) +
# scale_color_discrete(labels = c("QMR", "DSR")) +
  theme_grey()+
  theme(legend.position = "bottom") +
  facet_wrap(~dist)
```



### for our invented distribution


```{r, fig.width=16, message=FALSE, warning=FALSE}


norm<-ggplot(results[-1,] %>% melt(id = 'wrong_tau'), 
       aes(x = wrong_tau, y= value, color = variable)) +
geom_point(size = 2) +
# ggtitle(TeX('Variance Elements - The Normal Distribution Density'),
#         subtitle = TeX('$\\tau = 0.99$ and $0.5<\\tau_{w}<0.99$'))+
xlab(TeX('$\\tau_{w}$')) +
guides(color = guide_legend(title=NULL)) +
scale_color_discrete(labels = lapply(c('$\\left(\\Phi^{-1}\\right)^{2}\\left(\\tau_{w}\\right)-\\left(\\Phi^{-1}\\right)^{2}\\left(\\tau\\right)$',                                 '$\\frac{\\tau\\left(1-\\tau\\right)}{\\tau_{w}\\left(1-\\tau_{w}\\right)}$'), TeX)) +
  theme_grey()+
  theme(legend.position = "None") 
  

invented<-ggplot(results[-1,] %>% melt(id = 'wrong_tau'), 
       aes(x = wrong_tau, y= value, color = variable)) +
geom_point(size = 2) +
# ggtitle(TeX('Variance Elements - The Absolute Value density'),
#         subtitle = TeX('$\\tau = 0.99$ and $0.5<\\tau_{w}<0.99$')) +
xlab(TeX('$\\tau_{w}$')) +
guides(color = guide_legend(title=NULL)) +
scale_color_discrete(labels = lapply(c('$\\left(\\Phi^{-1}\\right)^{2}\\left(\\tau_{w}\\right)-\\left(\\Phi^{-1}\\right)^{2}\\left(\\tau\\right)$',                                 '$\\frac{\\tau\\left(1-\\tau\\right)}{\\tau_{w}\\left(1-\\tau_{w}\\right)}$'), TeX))+
  theme_grey()
  # +theme(legend.position = "None")


grid.arrange( grobs = list(norm, invented), ncol =2,  widths = c(5.3,6.7))
help(legend)

```


